
## Principios Éticos de la IA según la UNESCO

> "El rápido auge de la inteligencia artificial (IA) ha generado nuevas oportunidades a nivel global: desde facilitar los diagnósticos de salud. Esta tecnología plantea profundos dilemas éticos, que surgen del potencial que tienen los sistemas basados en IA para reproducir prejuicios, contribuir a la degradación del clima y amenazar los derechos humanos, entre otros"  UNESCO.

* Proporcionalidad e inocuidad.
* Seguridad y protección.
* Equidad y no discriminación.
* Sostenibilidad.
* Derecho a la intimidad y protección de datos.
* Supervisión y decisiones humanas.
* Transparencia y explicabilidad.
* Responsabilidad y rendición de cuentas.
* Sensibilización y educación.
* Gobernanza y colaboración adaptativa.

### Proporcionalidad e inocuidad

La IA debe utilizarse de manera proporcional con el objetivo que se persigue, no debe utilizarse para fines que sean excesivos o innecesarios.

La UNESCO establece que los marcos de acceso a los datos deben ser sostenibles, respetar la privacidad y fomentar un mejor entrenamiento y validación de los modelos de IA. Los sistemas de ==IA deben ser inocuos==, es decir, no deben causar daños físicos, psicológicos o ambientales.

### Seguridad y protección

Este principio establece que los sistemas de IA deben ser diseñados y utilizados de manera que se ==minimicen los riesgos== de daños no deseados y vulnerabilidades a los ataques.

Las vulnerabilidades a los ataques son debilidades en los sistemas de IA que pueden ser explotadas por los atacantes. La UNESCO establece que los marcos de acceso a los datos deben ser sostenibles, respetar la privacidad y fomentar un mejor entrenamiento y validación de los modelos de IA.

### Equidad y no discriminación

Este principio establece que la IA debe promover la justicia social, salvaguardar la equidad y luchar contra todo tipo de discriminación.

La equidad significa que todos los seres humanos, independientemente de su raza, género, religión, etnia, discapacidad, etc, deben tener acceso a los beneficios de la IA.

La IA debe estar diseñada y utilizada de manera que ==no discrimine== a ningún grupo de personas.

### Sostenibilidad

La IA puede tener un impacto positivo o negativo en la sostenibilidad, dependiendo de cómo se aplique.

La IA puede contribuir a la sostenibilidad de varias maneras, como las siguientes:

* Mejorando la eficiencia y la productividad.
* Reduciendo el consumo de recursos.
* Protegiendo el medio ambiente.

Sin embargo, la IA también puede tener un impacto negativo en la sostenibilidad, por motivos como los siguientes:

* Provocación de pérdida de empleos.
* Aumento o agravamiento de la desigualdad.

### Derecho a la intimidad y protección de datos

Es un derecho humano fundamental que protege la dignidad, la autonomía y la capacidad de actuar de los seres humanos.

El derecho a la protección de datos se refiere al derecho de las personas a que sus datos personales se recopilen, utilicen y compartan de manera legal, justa y transparente.

Los actores de la IA deben tomar medidas para ==proteger los datos personales== de las personas.

### Supervisión y decisiones humanas

Es necesaria para garantizar que los sistemas de IA se desarrollen, utilicen y desplieguen de manera ética.

Los sistemas de IA pueden utilizarse para apoyar la toma de ==decisiones humanas==, pero ==no deben reemplazarla==.

Un sistema de IA nunca podrá reemplazar la responsabilidad final de los seres humanos y su obligación de rendir cuentas.

### Transparencia y explicabilidad

La transparencia es la capacidad de comprender cómo funciona un sistema de IA. Esto incluye la capacidad de analizar los datos utilizados para entrenar el sistema, el algoritmo que se utiliza para procesar los datos y los resultados.

La explicabilidad es la capacidad de explicar ==cómo se llegó a un resultado determinado== por un sistema de IA, qué factores influyeron en él y por qué el sistema tomó la decisión que tomó.

Sin transparencia es difícil identificar y abordar los sesgos en los sistemas de IA.

### Responsabilidad y la rendición de cuentas en los sistemas

La responsabilidad es la obligación de responder por los actos u omisiones. En el caso de los sistemas de IA, ==la responsabilidad recae en los actores de la IA, que son las personas o entidades que desarrollan, utilizan o despliegan sistemas de IA==.

Los actores de la IA deben asumir su responsabilidad ética y jurídica a lo largo de todo el ciclo de vida de los sistemas de IA.

Deberían elaborarse mecanismos adecuados de supervisión, evaluación del impacto y auditoría en general.

### Sensibilización y la educación

La sensibilización es importante para que las personas entiendan cómo funcionan los sistemas de IA y cuáles son sus posibles impactos.

La sensibilización sobre la IA debe centrarse en los siguientes temas:

* ¿Cómo funcionan los sistemas de IA?
* Los posibles impactos de los sistemas de IA.
* Los principios éticos de la IA.

La educación sobre la IA debe centrarse en los siguientes temas:

* Competencias digitales.
* Competencias de pensamiento crítico.
* Educación abierta y accesible.

### Gobernanza y colaboración adaptativas y de múltiples partes interesadas

La gobernanza adaptativa implica el desarrollo de marcos y mecanismos que puedan evolucionar a medida que la tecnología y las prácticas de la IA cambian.

La colaboración de múltiples partes interesadas puede ayudar a garantizar que la IA sea inclusiva, equitativa y beneficiosa para todos. Al involucrar a una amplia gama de actores, es más probable que se consideren una variedad de perspectivas y necesidades.

Pautas que pueden guiar la gobernanza y colaboración:

* Los procesos deben ser transparentes y permitir la participación de todos los interesados.

* Los marcos y mecanismos deben ser flexibles y capaces de adaptarse a los cambios.

* Los procesos deben ser equitativos y no discriminatorios.